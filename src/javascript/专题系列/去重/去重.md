# 去重

**去重**: 就是去除一个数据结构中相同的部分, 日常开发中主要操作的是 **数组**

例如: [1, 1, 2, 2, 3, 3, 3] 在这个数组中,我们发现有数字是重复,那么我们要如何去除相同的部分呢?

## 兼容版

兼容性最好的方法就是只采用, `for` 循环进行

```js
const test = [1, 1, 2, 2, 3, 3, 3]

function unique(arr) {
  const res = []
  for (let i = 0, arrLen = arr.length; i < arrLen; i++) {
    const resLen = res.length
    let j = 0
    for (; j < resLen; j++) {
      if (arr[i] === res[j]) break
    }
    // 如果 arr[i] 是唯一值,那么在res中就不会找到,所以 j 会遍历到最后
    // 也就是 j === resLen
    if (j === resLen) {
      res.push(arr[i])
    }
  }
  return res
}

console.log(unique(test))
```

这方法简单, 不过用算法复杂度来说的话, 他就有点麻烦了, 最坏的情况时间复杂度达到了 `O(n²)`, 不过他就好在兼容性好,放哪都能执行

## indexOf 和 includes

其实我感觉日常,大家还是比较熟悉这两个 `api`, 这个的好处就是方便

```js
const test = [1, 1, 2, 2, 3, 3, 3]

function unique(arr) {
  const res = []
  for (let i = 0, arrLen = arr.length; i < arrLen; i++) {
    // 没有就添加进去, 兼容性还是 indexOf 好, includes IE 还不兼容,上次踩了一回坑
    if (!res.includes(arr[i])) {
      // if(res.indexOf(arr[i]) === -1) {
      res.push(arr[i])
    }
  }
  return res
}

console.log(unique(test))
```

在这里还是一样, 时间复杂度比较高, 在第一版双重 `for` 循环中, 我们是自己遍历了 `res` 数组, 在这一版中,只是使用了系统 `API` 帮助我们遍历罢了,那我们怎么样才能只用一遍循环就完事了? 在 `O(n)` 时间复杂度内完成呢?

我们来把数组排序一下,再看看

```js
const test = [2, 1, 1, 3, 4, 2, 3, 4, 3, 3]

function unique(arr) {
  // 排序示例
  const tempArr = arr.slice().sort((a, b) => a - b)
  const res = []
  let seen
  for (let i = 0; i < tempArr.length; i++) {
    const value = tempArr[i]
    // 第一个元素直接进来, 第二个元素需要和上一的元素进行比较
    if (!i || seen !== value) {
      res.push(value)
    }
    seen = value
  }
  return res
}

console.log(unique(test)) // [1, 2, 3, 4]
```

可以看出我们只在一遍循环中, 完成了去重操作, 对比是否相同的操作,仅对于当前元素和上一个元素, 因为是有序的.

那么我们就可以根据排序和没排序来编写我们的去重工具函数了

## uniqueApi

联合排序和没排序的版本

```js
const test = [2, 1, 1, 3, 4, 2, 3, 4, 3, 3]

// isSorted 是否是一个有序的数组
function unique(arr, isSorted) {
  const res = []
  let seen
  for (let i = 0; i < arr.length; i++) {
    const value = arr[i]
    if (isSorted) {
      // 第一个元素直接进来, 第二个元素需要和上一的元素进行比较
      if (!i || seen !== value) {
        res.push(value)
      }
      seen = value
    } else if (!~res.indexOf(value)) {
      res.push(value)
    }
  }
  return res
}

console.log(unique(test)) // [ 2, 1, 3, 4 ]
test.sort((a, b) => a - b)
console.log(unique(test, true)) // [ 1, 2, 3, 4 ]
```

这样我们就可以根据有没有排序选择对应的版本,来提升那么一丢丢的性能, 哈哈~

## 优化

我们知道, 在 **数组中可以存放任意类型的数据** , 那么我们对每种数据类型都采用这样 `===` 操作, 来进行比较, 那么如果有特殊情况呢, 比如 'a' 和 'A', 要算是同一个 **值** 呢? 这个需求还算合理吧, 哈哈~

我们可以提供一个方法,让使用的人来处理一下比较的值, 比如让让元素执行 `'A'.toLowerCase()` , 这样他来决定, 应该算是一个比较理想的状态.

```js
const test = [2, 1, 1, 3, 4, 2, 3, 4, 3, 3, 'a', 'A']

// iterate: 迭代, 重复
function unique(arr, isSorted, iterate) {
  const res = []
  let seen = []
  for (let i = 0; i < arr.length; i++) {
    const value = arr[i]
    const computed = iterate ? iterate(value, i, arr) : value
    if (isSorted) {
      // 使用用户计算后的值进行比较
      if (!i || seen !== computed) {
        // 修改
        res.push(value) // 给用户返回的,可不需要被处理的值
      }
      seen = computed
    } else if (iterate) {
      // 采用seen进行比较,seen是保存了计算过后的值,不然 iterate 就没有意义了
      if (!~seen.indexOf(computed)) {
        res.push(value)
        seen.push(computed)
      }
    } else if (!~res.indexOf(value)) {
      res.push(value)
    }
  }
  return res
}

console.log(unique(test)) // [ 2, 1, 3, 4, 'a', 'A' ]
console.log(
  unique(test, false, val => {
    if (typeof val === 'string') return val.toLowerCase()
    return val
  })
) // [ 2, 1, 3, 4, 'a' ]
```

好了,在这最后一版中,我们实现了一个相对完善的去重方法, 这个方法是来自于 **underscore** 提供的一个 `API`, 其中三个参数分别是

- arr: 需要去重的数组
- isSorted: 是否有序
- iterate: 操作比较值的方法

## 其余去重方案

介绍完 **underscore** 相对完善的方案之后, 我们来看看其余的去重方案, 开拓视野, 查看不同方案的坑

### 1.filter 去重

直接过滤的版本

```js
const test = [2, 1, 1, 3, 4, 2, 3, 4, 3, 3, 'a', 'A']

function unique(arr) {
  // 如果重复,indexOf 返回的是第一个item的下标, 与当前 idx 不同
  return arr.filter((item, idx) => arr.indexOf(item) === idx)
}

console.log(unique(test)) // [ 2, 1, 3, 4, 'a', 'A' ]
```

排序的版本

```js
const test = [2, 1, 1, 3, 4, 2, 3, 4, 3, 3, 'a', 'A']
function unique(arr) {
  // 一样,下标0直接进入,其他的和前一项对比即可
  return arr
    .slice()
    .sort()
    .filter((item, idx, arr) => !idx || item !== arr[idx - 1])
}
console.log(unique(test)) // [ 1, 2, 3, 4, 'A', 'a' ]
```

### 2.利用对象的去重

我们上面都是在利用 **数组** 这个数据结构再帮忙存储是否重复出现, 而我们现在使用 **对象** 来帮助我们完成这个辅助工作, 也就相当于我们说的 **哈希表**

```js
const test = [2, 1, 1, 3, 4, 2, 3, 4, 3, 3]

function unique(array) {
  const obj = {}
  return array.filter(function (item) {
    // 如果对象拥有属性,则证明已经出现过,没有出现的则设置一下
    return obj.hasOwnProperty(item) ? false : (obj[item] = true)
  })
}

console.log(unique(test)) // [ 2, 1, 3, 4 ]
```

**哈希表** 的访问是 `O(1)` 的,则可能比我们的 `indexOf` 要好一点,不过也有对应的坑, 对象只能使用 **字符串作为键**, 所以 `1` 和 `'1'` 数字和字符串会共享一个 `key` 那么就存在误判的情况了

这种情况,我们要处理其实也简单,为不同类型加上对应标识就行了,就类似这样

```js
function unique(array) {
  const obj = {}
  return array.filter(function (item) {
    // 修改,增加类型
    return obj.hasOwnProperty(typeof item + item)
      ? false
      : (obj[typeof item + item] = true)
  })
}
```

不过都是 js 中对象可是有很多种,该如何避免呢? 对象可都是 `object`, 我们可以使用 `JSON.stringify` 把 item 转换成为字符串, 操作方式很多,我们不过为了去重,我们好像可以不用选择过于复杂的方案. 比如使用 `Map` 就可以解决这个问题,不用 `typeof`

### 3.ES6 的加入

随着 `ES6` 的到来，去重的方法又有了进展，比如我们可以使用 `Set` 和 `Map` 数据结构，以 `Set` 为例，`ES6` 提供了新的数据结构 `Set`。它类似于数组，但是成员的值都是唯一的，没有重复的值。

是不是感觉就像是为去重而准备的？让我们来写一版：

```js
const test = [1, 2, 1, 1, '1']

function unique(array) {
  return Array.from(new Set(array))
}

console.log(unique(test)) // [1, 2, "1"]
```

甚至可以再简化下：

```js
function unique(array) {
  return [...new Set(array)]
}
```

还可以再简化下：

```js
const unique = a => [...new Set(a)]
```

此外，如果用 Map 的话：

```js
function unique(arr) {
  const seen = new Map()
  return arr.filter(a => !seen.has(a) && seen.set(a, 1))
}
```

我们可以明显看到随着 `ES6` 的到来, 很多操作都变得那么简单, 相信以后的开发也会越来越高效。
